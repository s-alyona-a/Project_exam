# Project_exam (Сергеева Алёна, БКЛ-212)
# LikeDumaBot
## https://t.me/LikeDumaBot

## Тема проекта: "Гарри Поттер и..."  
Проект представляет собой telegram-bot, который умеет генерировать сообщения в стиле Александра Дюма.

### Ход работы:  
<b> Данные и обучение. </b>  
1. Для обучения модели были скачаны тексты произведений автора с сайта Lib.Ru и сохранены в текстовом файле "train_text.txt" (были использованы <b> requests </b> и <b> BeautifulSoup </b>) #файл write_full_text.py
2. После этого с помощью <b> Counter </b> текст был разделён на символы, каждому из которого присваивался свой номер - весь текст также был представлен как последовательность номеров символов
3. Далее создавалась обучающая выборка - модель должна была бы предсказывать следующий символ (то есть целевая переменная - строка, сдвинутая на 1 символ вправо). Например, если модель получает на вход строку " кот съел собак" - правильным ответом для неё будет "кот съел собаку".
4. Была написана функция для генерирования текста: программа получаем первый символ - пробел, а после него воспроизводит постепенно каждый следующий символ, опираясь на предыдущую последовательность
5. Обучение модели было реализовано с помощью библиотеки <b> torch </b> и идеи <b> LSTM </b>, когда модель помнит все предыдущие инпуты. Для обучения символы были векторизованы.
6. Дальше работа с <b> нейросетью </b> - было проведено 10000 эпох обучения, по мере прохождения которых функция потерь уменьшалась - то есть модель бы делала меньше ошибок (можно было бы провести ещё больше эпох для лучшего результата, но это на самом деле долгий процесс)
7. После этого модель была сохранена в файл model.pt, откуда и вызывалась для дальнейшей генерации текста.

<b> Tg-bot. </b>  
1. Для генерирования отрезка текста используется команда <i> /phrase </i>, у которой можно выбрать параметр - количество символов в сгенерированной фразе.
2. Кроме этого была добавлена кнопка <i> /who_r_u_2day </i>, которая отвечает пользователю рандомным стикером из стикерпака с мушкетёрами.  
3. Кнопки <i> /start </i> и <i> /help </i> помогают пользователю с функционалами.
4. А если пользователь вдруг решит ввести свой текст - он получит мем с Друзём или с кадром из "Банд Нью-Йорка".
5. А ещё у бота есть фоточка и описание, а для удобства вызова команд - клавиатура.

<b> Загрузка. </b>  
* Я загрузила бот на pythonanywhere, так что всё должно хорошо работать

<b> Немного о структуре. </b>  
- Собственно бот: bot.py  
- Подготовка данных: write_full_text.py  
- Обучение модели: one_more_model.py  
- Файл с функцией генерации предложения: new_model_test.py  
- Модель: model.pt  
- Текст: train_text.txt  

### Замечания
Бот на самом деле не всегда красиво формулирует output, и для улучшения модели можно будет ещё попробовать обучать её большее количество эпох. Тем не менее, по большей части отдельные слова очень даже осмысленны. Наверное, если бы применился морфологический парсинг, результат был бы лучше, но, честно говоря, я не придумала, как можно объединить это с посимвольной генерацией текста....  

В процессе создания я также пробовала использовать <b> Tensorflow </b> и <b> keras </b> и там же <b> токенизаоры nltk </b> (тоже идея в том, чтобы генерировать текст посимвольно), но получалась сильная несуразица (все это лежит в папке Attempts, в том числе файлы, содержащие веса для нейросети)  

![image](https://user-images.githubusercontent.com/90251910/227872187-a954601b-23f3-4700-a223-90e496f92cf7.png)
